"use strict";(self.webpackChunkdeveloper_playcanvas_com=self.webpackChunkdeveloper_playcanvas_com||[]).push([[8383],{42286:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>n,metadata:()=>o,toc:()=>d});var r=s(85893),i=s(11151);const n={title:"Texture",sidebar_position:15},a=void 0,o={id:"user-manual/assets/textures/index",title:"Texture",description:"A texture is an image that can be assigned to a material and then applied to a graphical primitive.",source:"@site/docs/user-manual/assets/textures/index.md",sourceDirName:"user-manual/assets/textures",slug:"/user-manual/assets/textures/",permalink:"/user-manual/assets/textures/",draft:!1,unlisted:!1,editUrl:"https://github.com/playcanvas/developer.playcanvas.com/tree/dev/docs/user-manual/assets/textures/index.md",tags:[],version:"current",sidebarPosition:15,frontMatter:{title:"Texture",sidebar_position:15},sidebar:"userManualSidebar",previous:{title:"Template",permalink:"/user-manual/assets/templates"},next:{title:"Texture Compression",permalink:"/user-manual/assets/textures/texture-compression"}},l={},d=[{value:"Importing Textures",id:"importing-textures",level:2},{value:"Texture Properties",id:"texture-properties",level:2},{value:"Texture Filtering",id:"texture-filtering",level:3},{value:"Anisotropy",id:"anisotropy",level:3},{value:"Texture Addressing",id:"texture-addressing",level:3},{value:"Max Texture Size",id:"max-texture-size",level:2}];function u(e){const t={a:"a",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",ul:"ul",...(0,i.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(t.p,{children:["A texture is an image that can be assigned to a ",(0,r.jsx)(t.a,{href:"/user-manual/assets/materials",children:"material"})," and then applied to a graphical primitive."]}),"\n",(0,r.jsx)(t.h2,{id:"importing-textures",children:"Importing Textures"}),"\n",(0,r.jsx)(t.p,{children:"There are 3 ways you can import texture assets into PlayCanvas:"}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsx)(t.li,{children:"Drag and drop images into the Assets panel."}),"\n",(0,r.jsx)(t.li,{children:"Select 'Upload' from the context menu in the Assets panel and select an image using the file browser."}),"\n",(0,r.jsx)(t.li,{children:"Import an FBX file that embeds textures."}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"Supported image formats are:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"JPG"}),"\n",(0,r.jsx)(t.li,{children:"PNG"}),"\n",(0,r.jsx)(t.li,{children:"AVIF"}),"\n",(0,r.jsx)(t.li,{children:"WEBP"}),"\n",(0,r.jsx)(t.li,{children:"GIF"}),"\n",(0,r.jsx)(t.li,{children:"TGA"}),"\n",(0,r.jsx)(t.li,{children:"BMP"}),"\n",(0,r.jsx)(t.li,{children:"TIF"}),"\n",(0,r.jsx)(t.li,{children:"HDR"}),"\n",(0,r.jsx)(t.li,{children:"EXR"}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"Imported JPG, PNG, AVIF, WebP and GIF files remain in their original format."}),"\n",(0,r.jsx)(t.p,{children:"GIF, TGA, BMP and TIF image types will be converted to JPG or PNG on import. If the imported image has transparency, it will be converted to PNG. Otherwise, it will be converted to JPG."}),"\n",(0,r.jsxs)(t.p,{children:["HDR and EXR are ",(0,r.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/High-dynamic-range_imaging",children:"high dynamic range formats"})," formats. Images of these types are converted to PNG on import and marked as being stored in RGBM format. RGBM essentially stores a multiplier for RGB values in the PNG's alpha channel, enabling the compression of an HDR format into a low dynamic range format."]}),"\n",(0,r.jsx)(t.p,{children:"By default, imported images will be resized to the nearest power of two. For example, an image that is 323x414 will be resized to 256x512 on import. This is done because the graphics engine cannot utilize mipmapping with non-power of two textures. However, this behavior can be overridden by disabling the 'Textures POT' setting in the Asset Tasks panel before importing a non-power of two texture."}),"\n",(0,r.jsx)(t.h2,{id:"texture-properties",children:"Texture Properties"}),"\n",(0,r.jsx)(t.p,{children:"Selecting a texture's thumbnail in the Assets panel will load it into the Inspector panel. Note that you can multi-select textures and edit the whole selection simultaneously in the Inspector."}),"\n",(0,r.jsx)(t.p,{children:"A texture shares the standard set of asset properties (ID, name, tags and so on). But it's also has some texture-specific properties."}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{src:"/images/user-manual/assets/textures/texture-properties.png",alt:"Texture Properties"})}),"\n",(0,r.jsx)(t.h3,{id:"texture-filtering",children:"Texture Filtering"}),"\n",(0,r.jsx)(t.p,{children:"Texture filtering gives control over how the color of a texture mapped pixel is calculated. 'Point' applied no filtering whereas 'Linear' will interpolate the color of a texel with those of its neighbors. This produces better visual results, particularly as a texture is minimized (where the texture occupies fewer pixels on the screen than it has texels)."}),"\n",(0,r.jsx)(t.h3,{id:"anisotropy",children:"Anisotropy"}),"\n",(0,r.jsx)(t.p,{children:"When textures are viewed on surfaces at an oblique angle, quality can suffer and they can appear blurred. To fix this problem, you can set a value for anisotropy. See how different anisotropy values can affect the appearance of a texture:"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{src:"/images/user-manual/assets/textures/anisotropy.png",alt:"Anisotropy"})}),"\n",(0,r.jsx)(t.p,{children:"Note that as anisotropy increases, the cost of sampling the texture on the GPU also increases."}),"\n",(0,r.jsx)(t.h3,{id:"texture-addressing",children:"Texture Addressing"}),"\n",(0,r.jsx)(t.p,{children:"The texture addressing properties give you control over how a texture is sampled for texture coordinates outside the range 0 to 1. See how the different modes affect the sprite below:"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{src:"/images/user-manual/assets/textures/texture-address.png",alt:"Addressing"})}),"\n",(0,r.jsx)(t.h2,{id:"max-texture-size",children:"Max Texture Size"}),"\n",(0,r.jsxs)(t.p,{children:["Different devices can support different texture sizes. Using ",(0,r.jsx)(t.a,{href:"https://webglreport.com/",children:"WebGL report"})," on the device and browser, we can see the max size supported."]}),"\n",(0,r.jsx)(t.p,{children:"For example, this is from a MacBook Pro 16 inch (2020) laptop with Chrome which shows support up to 16384x16384."}),"\n",(0,r.jsx)("img",{loading:"lazy",src:"/images/user-manual/assets/textures/mac-webgl-report.png",alt:"Macbook Pro WebGL report",width:"600"}),"\n",(0,r.jsx)(t.p,{children:"Whereas on a Samsung S7 mobile device, only 4096x4096 is supported."}),"\n",(0,r.jsx)("img",{loading:"lazy",src:"/images/user-manual/assets/textures/samsung-s7-webgl-report.jpg",alt:"Samsung S7 WebGL report",width:"600"}),"\n",(0,r.jsx)(t.p,{children:"If the engine attempts to utilize a texture that exceeds the max texture size reported by WebGL, it will resize it down to this maximum size at runtime. Note that this is only done for texture loaded from images (PNG, JPG, AVIF, WebP, GIF). Compressed textures cannot be resized at runtime and will simply fail to render if they are too large for the device."}),"\n",(0,r.jsx)(t.p,{children:"If you would like to avoid downsizing at runtime, at the time of writing (Fri 23 Oct 2020), 4096x4096 is very widely supported with some developers even opting for 2048x2048 which is guaranteed to work everywhere."})]})}function p(e={}){const{wrapper:t}={...(0,i.a)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(u,{...e})}):u(e)}},11151:(e,t,s)=>{s.d(t,{Z:()=>o,a:()=>a});var r=s(67294);const i={},n=r.createContext(i);function a(e){const t=r.useContext(n);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(n.Provider,{value:t},e.children)}}}]);